<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <meta content="#Secim2023 Project" name="VRL Lab @ Sabanci University">
        <meta content="disinformation, social bot detection, coordinated activity detection, dezenformasyon, sosyal bot tespiti, koordinasyon tespiti" name="keywords">
        <meta content="Copyright (c) 2022 VRL Lab @ Sabanci University" name="Copyright">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta property="og:title" content="#Secim2023 Project @ VRL Lab">
        <meta property="og:type" content="website">
        <meta property="og:url" content="http://secim2023.biz">
        <meta property="og:image" content="http://secim2023.biz/img/secim2023-logo.png">
        <meta property="og:image:type" content="image/png">
        <meta property="og:image:width" content="400">
        <meta property="og:description" content="Bu platform üzerinden 2023 Cumhurbaşkanlığı Seçimleri için gerçekleştirdiğimiz dezenformasyon ve koordinasyonlu aktivite ile mücadele projesine ait raporlar ve makaleler yayınlıyoruz.">
        <link id="page_favicon" href="img/favicon.ico" rel="icon" type="image/x-icon" />
        
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/lipis/flag-icons@6.6.6/css/flag-icons.min.css"/>
        <script src="/js/jquery.min.js"></script>
        <script src="/js/popper.min.js"></script>
        <script src="/js/bootstrap.bundle.min.js"></script>
        <script src="/js/fa-all.js" data-auto-replace-svg="nest"></script>
        <script src="/js/multilingual.js"></script>

        <link rel="stylesheet" href="/css/bootstrap.min.css">

        <link type="text/css" rel="stylesheet" href="/css/hover-min.css" />
        <link type="text/css" rel="stylesheet" href="/css/academicons.min.css" />
        
        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-KMQ3V513ZY"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-KMQ3V513ZY');
        </script>
        
        <title>#Secim2023</title>

        <script type="text/javascript">
            $(document).ready(function () {
                $('[data-toggle="tooltip"]').tooltip();
                $('#header-container').load('/components/header.html', function() {
                  setLang(getCookie('pagelang', 'en'));
                });
                $('#footer-container').load('/components/footer.html', function() {
                  setLang(getCookie('pagelang', 'en'));
                });
            });
            $(window).on('load', function () {
              setLang(getCookie('pagelang', 'en'));
            });
        </script>
    </head>

    <body>

        <div id="header-container"></div>
        
        <div class="container">
            <div class="row my-5 justify-content-center">
                
                <div class="col-10">
                    <h4>TurkishBERTweet: Fast and Reliable Large Language Model for Social Media Analysis</h4>
                    <p>
                        <b>Abstract</b>: Turkish is one of the most popular languages in the world. Wide us of this language on social media platforms such as Twitter, Instagram, or Tiktok and strategic position of the country in the world politics makes it appealing for the social network researchers and industry. To address this need, we introduce TurkishBERTweet, the first large scale pre-trained language model for Turkish social media built using almost 900 million tweets. The model shares the same architecture as base BERT model with smaller input length, making TurkishBERTweet lighter than BERTurk and can have significantly lower inference time. We trained our model using the same approach for RoBERTa model and evaluated on two text classification tasks: Sentiment Classification and Hate Speech Detection. We demonstrate that TurkishBERTweet outperforms the other available alternatives on generalizability and its lower inference time gives significant advantage to process large-scale datasets. We also compared our models with the commercial OpenAI solutions in terms of cost and performance to demonstrate TurkishBERTweet is scalable and cost-effective solution. As part of our research, we released TurkishBERTweet and fine-tuned LoRA adapters for the mentioned tasks under the MIT License to facilitate future research and applications on Turkish social media.
                    </p>
                    <p>
                        Najafi, Ali and Varol, Onur. TurkishBERTweet: Fast and Reliable Large Language Model for Social Media Analysis. arXiv:2311.18063 (2023).
                    </p>
                </div>

                <div class="col-10">
                    <span style="margin-right: 1em;"><a href="/posts/2023-turkishbertweet.pdf" target="_blank"><i class="ai ai-arxiv"></i> PDF</a></span>
                    <span style="margin-right: 1em;"><a href="https://github.com/ViralLab/TurkishBERTweet" target="_blank"><i class="ai ai-open-access"></i> Github</a></span>
                    <span style="margin-right: 1em;"><a href="https://huggingface.co/VRLLab/TurkishBERTweet" target="_blank"><i class="ai ai-open-data"></i> HuggingFace</a></span>
                </div>
            </div>
        </div>
        
        <div id="footer-container"></div>

    </body>
</html>